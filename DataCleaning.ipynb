{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, isdir\n",
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SOURCE_PATH = './Datasets/'\n",
    "CLEANED_DATASETS_PATH = './Cleaned Datasets/'\n",
    "COLUMNS_TO_DROP = ['id', 'unnamed:_0']\n",
    "COLUMNS_WITH_AMOUNT = ['pricecap', 'price', 'shareprice', 'marketcap', 'gbp', 'total_raised', 'valuation',\n",
    "                       'share_price', 'market_cap', 'master_cap', 'revenue', 'market_value_apr_2022',\n",
    "                       'annual_revenue_in_usd', 'annual_net_income_in_usd', 'market_value', 'marketvalue',\n",
    "                       'annual_revenue', 'revenue_2022', 'net_income', 'annual_results_for_year_ending', 'total_assets_in_usd', 'total_liabilities_in_usd', 'total_equity_in_usd', 'market_value_(jan_1st_2020)', 'market_value_(jan-07-2022)', 'market_value_jan_2020', 'market_value_jan_2021', 'market_value_jan_2022']\n",
    "COLUMNS_WITH_NAME = ['name', 'company', 'ceo', 'founders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forbes_fr_cleaned.csv\n",
      "wiki_GioPonSPiz_cleaned.csv\n",
      "Wikipedia_MarScoToc_cleaned.csv\n",
      "famcap_germany_FR_cleaned.csv\n",
      "govuk_DeBiGa_cleaned.csv\n",
      "cbinsights_DDD_cleaned.csv\n",
      "cbinsights_iGMM_cleaned.csv\n",
      "globaldata_DeBiGa_cleaned.csv\n",
      "CompaniesMarketCap_GioPonSpiz_cleaned.csv\n",
      "companiesMarketCap_Avengers_cleaned.csv\n",
      "CompaniesMarketCap_MarScoToc_cleaned.csv\n",
      "companiesmarketcap_gren_cleaned.csv\n",
      "companiesmarketcap_DDD_cleaned.csv\n",
      "companiesmarketcap_iGMM_cleaned.csv\n",
      "disfold_Avengers_cleaned.csv\n",
      "disfold_iGMM_cleaned.csv\n",
      "Disfold_MarScoToc_cleaned.csv\n",
      "disfold_gren_cleaned.csv\n",
      "disfold_GioPonSpiz_cleaned.csv\n",
      "disfold_fr_cleaned.csv\n",
      "disfold_silvestri_cleaned.csv\n",
      "disfold_DeBiGa_cleaned.csv\n",
      "disfold_slyherin_cleaned.csv\n",
      "hitHorizons_Avengers_cleaned.csv\n",
      "ft_iGMM_cleaned.csv\n",
      "ft_Slytherin_cleaned.csv\n",
      "ft_gren_cleaned.csv\n",
      "ft_fr_cleaned.csv\n",
      "ft_DDD_cleaned.csv\n",
      "ft_silvestri_cleaned.csv\n",
      "valueToday_Avengers_cleaned.csv\n",
      "valueToday_GioPonSPiz_cleaned.csv\n",
      "valuetoday_silvestri_cleaned.csv\n",
      "valuetoday_fr_cleaned.csv\n",
      "valuetoday_slytherin_cleaned.csv\n",
      "valueToday_gren_cleaned.csv\n",
      "valueToday_iGMM_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "def clean_dataset(dataset):\n",
    "    dataset.columns = [re.sub(r'([a-z])([A-Z])', r'\\1 \\2', col).lower().replace(' ', '_') for col in dataset.columns]\n",
    "\n",
    "    for col in COLUMNS_TO_DROP:\n",
    "        if col in dataset.columns:\n",
    "            dataset.drop(col, axis=1, inplace=True)\n",
    "\n",
    "    dataset.dropna(axis=0, how='all', inplace=True)\n",
    "    dataset.fillna('', inplace=True)\n",
    "\n",
    "    for col in dataset:\n",
    "        dataset[col] = [', '.join(map(str, l)) if isinstance(l, list) else l for l in dataset[col]]\n",
    "\n",
    "        if dataset[col].dtype == object:\n",
    "            dataset[col] = dataset[col].str.lower()\n",
    "\n",
    "            if col in COLUMNS_WITH_NAME:\n",
    "                dataset[col] = clean_name_column(dataset[col])\n",
    "            elif col in COLUMNS_WITH_AMOUNT:\n",
    "                dataset[col] = clean_amount_column(dataset[col])\n",
    "            else:\n",
    "                dataset[col] = clean_general_column(dataset[col])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_multiplier(value):\n",
    "    if re.compile(r'\\s*million|\\sm').search(value):\n",
    "        return 1000000\n",
    "    elif re.compile(r'\\s*billion|\\sb').search(value):\n",
    "        return 1000000000\n",
    "    elif re.compile(r'\\s*trillion|\\st').search(value):\n",
    "        return 1000000000000\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def clean_amount(amount):\n",
    "    return re.sub(r'million|m|billion|b|trillion|t|usd|us|\\$|\\(([a-z0-9\\s]+)\\)', '', amount)\\\n",
    "        .replace(',', '.')\\\n",
    "        .strip()\n",
    "\n",
    "\n",
    "def clean_name_column(column):\n",
    "    return column.str.replace(r'dr. |dr |ceo |ceo:|none|mr. |mr |ms. |ms |not found|[,._?!()^\";@:#+*\\t]', '', regex=True)\\\n",
    "        .str.replace('\\\\n|\\s\\s+', ' ', regex=True)\\\n",
    "        .str.strip()\n",
    "\n",
    "\n",
    "def clean_general_column(column):\n",
    "    return column.str.replace('\\\\r\\\\n|employees:?|founded:?|none|not found|[\\\\n_?!()^\";#*\\t]', ' ', regex=True)\n",
    "\n",
    "\n",
    "def clean_amount_column(column):\n",
    "    l = []\n",
    "    for elem in column:\n",
    "        elem = elem.lower()\n",
    "        cleaned = clean_amount(elem)\n",
    "        multiplier = get_multiplier(elem)\n",
    "        if re.match('^[0-9]+(.[0-9]+)?$', cleaned):\n",
    "            l.append(int(float(cleaned) * multiplier))\n",
    "        else:\n",
    "            l.append(elem)\n",
    "\n",
    "    return l\n",
    "\n",
    "\n",
    "for directory in listdir(SOURCE_PATH):\n",
    "    dir_path = SOURCE_PATH + directory\n",
    "    if isdir(dir_path):\n",
    "        for f in listdir(dir_path):\n",
    "            file_path = dir_path + '/' + f\n",
    "            file_name = file_path[file_path.rfind('/') + 1:]\n",
    "            json_file_path = ''\n",
    "            df = None\n",
    "\n",
    "            if isfile(file_path):\n",
    "                if file_name.endswith('.csv'):\n",
    "                    json_file_name = file_name.replace('.csv', '_cleaned.csv')\n",
    "                    json_file_path = CLEANED_DATASETS_PATH + json_file_name\n",
    "                    print(json_file_name)\n",
    "\n",
    "                    try:\n",
    "                        df = pd.read_csv(file_path, encoding='utf-8', dtype=object)\n",
    "                    except UnicodeDecodeError:\n",
    "                        df = pd.read_csv(file_path, encoding='unicode_escape', dtype=object)\n",
    "                    except:\n",
    "                        print('ERROR: failed to read CSV file')\n",
    "\n",
    "                elif file_name.endswith('.json'):\n",
    "                    json_file_name = file_name.replace('.json', '_cleaned.csv')\n",
    "                    json_file_path = CLEANED_DATASETS_PATH + json_file_name\n",
    "                    print(json_file_name)\n",
    "                    df = pd.read_json(file_path, encoding='utf-8', dtype=object)\n",
    "                elif file_name.endswith('.jsonl'):\n",
    "                    json_file_name = file_name.replace('.jsonl', '_cleaned.csv')\n",
    "                    json_file_path = CLEANED_DATASETS_PATH + json_file_name\n",
    "                    print(json_file_name)\n",
    "                    df = pd.read_json(file_path, encoding='utf-8', lines=True, dtype=object)\n",
    "\n",
    "                if df is not None:\n",
    "                    df = clean_dataset(df)\n",
    "                    df = df.replace(r'^\\s*$', None, regex=True)\n",
    "                    json = re.sub(r'\\\\*/', '/', df.to_csv(index=False))\n",
    "                    json = unicodedata.normalize('NFKD', json).encode('ascii', 'ignore').decode('utf-8')\n",
    "                    print(json, file=open(json_file_path, encoding='utf-8', mode='w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}